<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>

  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>LoRA-A²</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>

  <style>
    .logo-bar {
      display: flex;
      justify-content: space-between;
      align-items: center;
      padding: 10px 40px;
    }

    .logo-left {
      height: 60px;
      transform: scale(1.25);
      transform-origin: left center;
    }

    .logo-right {
      height: 60px;
      transform: scale(0.75);
      transform-origin: right center;
    }
  </style>
</head>
<body>

  <div class="logo-bar">
    <img src="static/images/mllab_logo.png" alt="MLLab Logo" class="logo-left">
    <img src="static/images/acl_logo.png" alt="ACL Logo" class="logo-right">
  </div>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-2 publication-title">
              Towards Robust and Efficient Federated<br>
              Low-Rank Adaptation with Heterogeneous Clients
            </h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Jabin Koo</a><sup>*1</sup>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Minwoo Jang</a><sup>*2</sup>,</span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Jungseul Ok</a><sup>†12</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">{<sup>1</sup>Department of Computer Science and Engineering, <sup>2</sup>Graduate School of Artificial Intelligence}<br>
                      POSTECH, South Korea
                    </span>
                    
                    <span class="eql-cntrb"><small><br><sup>*</sup>Equal Contribution &nbsp; <sup>†</sup>Corresponding Author</small></span><br>
                    
                    <span class="author-block">
                      ACL 2025 (Main, Long)
                    </span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/abs/2410.22815" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/pseudope/LoRA-A2" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <figure class="image is-16by9">
        <img src="./static/images/main_figure.png" alt="Teaser image", style="max-width: 100%; height: auto;">
      </figure>
      <h2 class="subtitle has-text-centered">
        LoRA-A<sup>3</sup> comprises two key components: <strong>Alternating freeze</strong> and <strong>Adaptive rank selection</strong>.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser image -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Federated fine-tuning for Large Language Models (LLMs) has recently gained attention dueto the heavy communication overhead of transmitting large model updates.
            Low Rank Adaptation (LoRA) has been proposed as a solution, yet its application in federated learning is complicated by discordance in aggregation.
            Existing methods addressing this discordance often suffer from performance degradation at low ranks in heterogeneous data settings.
            In response, we introduce LoRA-A<sup>2</sup> (<b>Lo</b>w <b>R</b>ank <b>A</b>daptation with <b>A</b>lternating freeze and <b>A</b>daptive rank selection),
            which demonstrates robustness in challenging settings with low ranks and high data heterogeneity.
            Our experimental findings reveal that LoRA-A<sup>2</sup> maintains performance even under extreme heterogeneity and low rank conditions,
            achieving up to a 99.8% reduction in uploaded parameters compared to full fine-tuning without compromising performance.
            This adaptive mechanism boosts robustness and communication efficiency in federated fine-tuning,
            enabling the practical deployment of LLMs in resource-constrained environments.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Paper introduction -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Discordance Problem in Federated LoRA</h2>
        <div class="content has-text-justified">
          <p>
            When fine-tuning a pre-trained weight matrix \( W_0 \in \mathbb{R}^{d_1 \times d_2} \) to obtain \( W \),
            LoRA achieves this by decomposing \( \Delta W \), the update of the weight matrix,
            into smaller matrices \( B \in \mathbb{R}^{d_1 \times r} \) and \(A \in \mathbb{R}^{r \times d_2} \):
            \[ W = W_{0} + \Delta W = W_{0} + BA, \]
            where \( r \ll \{ d_1, d_2 \} \) denotes the rank of LoRA.
            With this approximation, the number of trainable parameters is reduced from \( d_1 \cdot d_2 \) to \( r \cdot (d_1 + d_2) \).

            LoRA presents a promising approach in Federated Learning (FL) for reducing communication costs,
            as only low rank module \( B \) and \( A \) are trained and transmitted,
            allowing the number of communicated parameters to be linearly reduced by the rank \( r \) of LoRA modules.
            However, the straightforward application of LoRA in FL introduces a significant issue known as discordance, primarily due to aggregation algorithms.
            In methods like FedAvg, where each weight is aggregated individually, discordance occurs between the actual and aggregated parameters. That is,
            \[ \sum_{k=1}^K w_k \Delta W_k = \sum_{k=1}^K w_k B_k A_k \neq \left( \sum_{k=1}^K w_k B_k \right) \left( \sum_{k=1}^K w_k A_k \right) \]
            in general, where \( \sum_{k=1}^K w_k = 1 \) with \( w_k \geq 0 \) for all \( k \in [K] \).
            One might consider aggregating \( \Delta W_k = B_kA_k \) directly to eliminate the discordance,
            but this approach entails decomposing \( \Delta W = \sum_{k=1}^K w_k \Delta W_k \) back into \( B \) and \( A \) for the next round,
            which is computationally unstable and non-trivial. 
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper introduction -->

<!-- Teaser image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <figure class="image is-16by16">
        <img src="./static/images/radar_plot_2x2.png" alt="Teaser image", style="max-width: 100%; height: auto;">
      </figure>
      <h2 class="subtitle has-text-centered">
        Main results, which is the same result from the paper.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser image -->

<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/carousel1.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          First image description.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/carousel2.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Second image description.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/carousel3.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
         Third image description.
       </h2>
     </div>
     <div class="item">
      <!-- Your image here -->
      <img src="static/images/carousel4.jpg" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Fourth image description.
      </h2>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->

<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{koo2024robustefficientfederatedlowrank,
        title={Towards Robust and Efficient Federated Low-Rank Adaptation with Heterogeneous Clients}, 
        author={Jabin Koo and Minwoo Jang and Jungseul Ok},
        year={2024},
        eprint={2410.22815},
        archivePrefix={arXiv},
        primaryClass={cs.LG},
        url={https://arxiv.org/abs/2410.22815}, 
  }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
